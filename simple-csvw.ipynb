{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with Web Standard CSVW using ChatGPT and Bing\n",
    "\n",
    "The purpose of this notebook is to learn how to use the web standard CSVW metadata for constructing a KG from the CSVW file using the CSVW library.\n",
    "\n",
    " -----\n",
    "\n",
    "**Me**\n",
    "I'm interested in how to construct structured metadata for CSV using the CSVW standard. How can I incorporate standardized vocabularies using JSON-LD?\n",
    "\n",
    "----\n",
    "\n",
    "**Bing**\n",
    "I'm glad you're interested in CSVW and JSON-LD. CSVW is a W3C standard for describing parts of tabular data, including cells, rows and columns². JSON-LD is a lightweight Linked Data format that is based on JSON and provides a way to help JSON data interoperate at Web-scale⁵. You can use JSON-LD to create a context that links object properties in a CSV file to concepts in an ontology⁷. This way, you can incorporate standardized vocabularies into your CSV metadata and make it more interoperable and machine-readable. For more details, you can check out the CSVW Primer² and the JSON-LD Playground⁵.\n",
    "\n",
    "Source: Conversation with Bing, 4/1/2023\n",
    "(1) CSV on the Web Working Group Wiki - W3. https://www.w3.org/2013/csvw/wiki/Main_Page Accessed 4/1/2023.\n",
    "(2) JSON-LD - JSON for Linking Data. https://json-ld.org/ Accessed 4/1/2023.\n",
    "(3) JSON-LD - Wikipedia. https://en.wikipedia.org/wiki/JSON-LD Accessed 4/1/2023.\n",
    "(4) Comma-separated values - Wikipedia. https://en.wikipedia.org/wiki/Comma-separated_values Accessed 4/1/2023.\n",
    "(5) Using metadata to describe CSV data - GOV.UK. https://www.gov.uk/government/publications/recommended-open-standards-for-government/using-metadata-to-describe-csv-data Accessed 4/1/2023.\n",
    "(6) Using CSV file format - GOV.UK. https://www.gov.uk/guidance/using-csv-file-format Accessed 4/1/2023.\n",
    "(7) JSON-LD 1.1 - W3. https://www.w3.org/TR/json-ld11/ Accessed 4/1/2023.\n",
    "\n",
    "----\n",
    "\n",
    "**Me**\n",
    "[Can you give me a simple example?](https://sl.bing.net/eXTdZ3Vkxk4)\n",
    "\n",
    "---\n",
    "\n",
    "**Bing**\n",
    "\n",
    "Sure, I can give you a simple example of how CSVW and JSON-LD work together. Suppose you have a CSV file called people.csv that contains some information about people's names, ages and occupations. It looks like this:\n",
    "\n",
    "```\n",
    "name,age,occupation\n",
    "Alice,25,teacher\n",
    "Bob,32,engineer\n",
    "Charlie,28,doctor\n",
    "```\n",
    "\n",
    "To describe this CSV file using CSVW and JSON-LD, you need to create a JSON file that contains some metadata about the CSV file. You can name it people.csv-metadata.json and put it in the same folder as the CSV file. The JSON file should look something like this:\n",
    "\n",
    "```\n",
    "{\n",
    "  \"@context\": \"http://www.w3.org/ns/csvw\",\n",
    "  \"url\": \"people.csv\",\n",
    "  \"tableSchema\": {\n",
    "    \"columns\": [\n",
    "      {\n",
    "        \"name\": \"name\",\n",
    "        \"datatype\": \"string\",\n",
    "        \"propertyUrl\": \"http://schema.org/name\"\n",
    "      },\n",
    "      {\n",
    "        \"name\": \"age\",\n",
    "        \"datatype\": \"integer\",\n",
    "        \"propertyUrl\": \"http://schema.org/age\"\n",
    "      },\n",
    "      {\n",
    "        \"name\": \"occupation\",\n",
    "        \"datatype\": \"string\",\n",
    "        \"propertyUrl\": \"http://schema.org/occupation\"\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "This JSON file uses the CSVW vocabulary to define the columns of the CSV file and their datatypes. It also uses the JSON-LD context to link the column names to standardized vocabularies from schema.org using propertyUrl. This way, you can express that the name column corresponds to the schema:name property, the age column corresponds to the schema:age property, and so on. This makes your CSV data more meaningful and interoperable with other data sources that use the same vocabularies.\n",
    "\n",
    "You can use various tools to validate, convert or visualize your CSVW metadata and data. For example, you can use csvlint.io to check if your CSVW metadata is valid and conforms to the standard. You can also use csvw-transform to convert your CSV data to RDF or JSON using your CSVW metadata. You can also use csvw-viewer to see how your CSV data looks like as a table with your CSVW metadata applied.\n",
    "\n",
    "Source: Conversation with Bing, 4/1/2023(1) CSV on the Web: A Primer - W3. https://www.w3.org/TR/tabular-data-primer/ Accessed 4/1/2023.\n",
    "(2) CSVW Maturity Levels | csvw-example. https://gss-cogs.github.io/csvw-example/ Accessed 4/1/2023.\n",
    "(3) CSV File Example. https://opencsvfile.com/example.html Accessed 4/1/2023.\n",
    "(4) csv — CSV File Reading and Writing — Python 3.11.2 documentation. https://docs.python.org/3/library/csv.html Accessed 4/1/2023.\n",
    "(5) CSV Files - Department of Scientific Computing. https://people.sc.fsu.edu/~jburkardt/data/csv/csv.html Accessed 4/1/2023.\n",
    "\n",
    "----\n",
    "\n",
    "**Me**\n",
    "How can I use this with google dataset search?\n",
    "\n",
    "----\n",
    "\n",
    "**Bing**\n",
    "You can use CSVW and JSON-LD with Google Dataset Search to make your CSV data more discoverable and accessible by other researchers and users. Google Dataset Search is a tool that helps you find datasets across the web using keywords, filters and facets¹. It relies on the schema.org/Dataset vocabulary to index and display datasets from various sources³. If you use CSVW and JSON-LD to describe your CSV data using the schema.org/Dataset vocabulary, you can increase the chances of your data being crawled and indexed by Google Dataset Search. You can also provide additional metadata such as title, description, license, publisher, date, etc. to make your data more informative and useful for potential users³. To use CSVW and JSON-LD with Google Dataset Search, you need to follow these steps:\n",
    "\n",
    "- Create a CSVW metadata file for your CSV data using JSON-LD and the schema.org/Dataset vocabulary. You can use the example I gave you earlier as a reference, or you can use other tools such as csvw-transform or csvw-generator to help you create the metadata file.\n",
    "- Host your CSV data and your CSVW metadata file on a publicly accessible web server. Make sure that the url property in your CSVW metadata file matches the actual URL of your CSV data file.\n",
    "- Add a link to your CSVW metadata file on the web page where you publish or share your CSV data. You can use a link tag with rel=\"describedby\" and type=\"application/ld+json\" attributes in the head section of your HTML page. For example:\n",
    "\n",
    "```\n",
    "<head>\n",
    "  <link rel=\"describedby\" type=\"application/ld+json\" href=\"people.csv-metadata.json\">\n",
    "</head>\n",
    "```\n",
    "\n",
    "- Test your CSVW metadata file using the Rich Results Test tool from Google. This tool will help you check if your metadata file is valid and compatible with Google Dataset Search. It will also show you a preview of how your dataset will appear in the search results.\n",
    "- Wait for Google to crawl and index your CSV data and your CSVW metadata file. This may take some time depending on various factors such as the size of your data, the frequency of updates, the popularity of your web page, etc. You can use Google Search Console to monitor the status of your indexing and troubleshoot any issues that may arise.\n",
    "- Once your CSV data and your CSVW metadata file are indexed by Google, you can use Google Dataset Search to find and access them using relevant keywords, filters and facets. You can also share the link to your dataset page with other users who may be interested in your data.\n",
    "\n",
    "I hope this helps you understand how to use CSVW and JSON-LD with Google Dataset Search. If you have any questions or feedback, please let me know.\n",
    "\n",
    "Source: Conversation with Bing, 4/1/2023(1) Dataset Search - Google. https://datasetsearch.research.google.com/ Accessed 4/1/2023.\n",
    "(2) Dataset Structured Data | Google Search Central | Documentation .... https://developers.google.com/search/docs/appearance/structured-data/dataset Accessed 4/1/2023.\n",
    "(3) Dataset Search. https://datasetsearch.research.google.com/search Accessed 4/1/2023.\n",
    "(4) An Analysis of Online Datasets Using Dataset Search ... - Google AI Blog. https://ai.googleblog.com/2020/08/an-analysis-of-online-datasets-using.html Accessed 4/1/2023.\n",
    "(5) Google Dataset Search | Hacker News. https://news.ycombinator.com/item?id=27068551 Accessed 4/1/2023.\n",
    "\n",
    "----\n",
    "\n",
    "**Me**\n",
    "Is Bing or Bing Chat able to also take advantage of this structured data on the web?\n",
    "\n",
    "----\n",
    "\n",
    "**Bing**\n",
    "\n",
    "Yes, Bing and Bing Chat are able to take advantage of structured data on the web. Bing uses structured data to refine search results, filter with greater accuracy and enhance the way results are displayed⁴. Bing supports various structured data formats such as Microdata, Microformats, RDFa, Schema.org and JSON-LD². Bing also provides a tool called Bing Webmaster Tools that helps you create, validate and test your structured data markup²³. You can use this tool to check if your structured data is valid and compatible with Bing search. You can also see a preview of how your structured data will appear in the search results.\n",
    "\n",
    "Bing Chat is a chat mode of Bing that helps you communicate with Bing in a natural and conversational way. Bing Chat uses structured data to understand the context and intent of your queries and provide relevant and informative responses. Bing Chat also uses structured data to generate rich and engaging suggestions for the next user turn. For example, if you ask Bing Chat about a movie, it may use structured data from IMDb or Rotten Tomatoes to show you the movie rating, genre, cast, etc. It may also suggest you to watch the trailer, read reviews or buy tickets for the movie. By using structured data on the web, Bing Chat can help you discover more information and perform various tasks with ease.\n",
    "\n",
    "I hope this helps you understand how Bing and Bing Chat use structured data on the web. If you have any questions or feedback, please let me know.\n",
    "\n",
    "Source: Conversation with Bing, 4/1/2023(1) Structured Data Testing Tools: 6 Options for Your Company. https://www.webfx.com/blog/seo/structured-data-testing-tools/ Accessed 4/1/2023.\n",
    "(2) Marking Up Your Site with Structured Data - Bing Webmaster Tools. https://www.bing.com/webmasters/help/markingup-your-site-with-structured-data-3a93e731 Accessed 4/1/2023.\n",
    "(3) Introducing JSON-LD Support in Bing Webmaster Tools. https://blogs.bing.com/webmaster/august-2018/Introducing-JSON-LD-Support-in-Bing-Webmaster-Tools Accessed 4/1/2023.\n",
    "(4) Bing Webmaster Tools. https://www.bing.com/webmasters/help/marking-up-your-site-with-structured-data-3a93e731 Accessed 4/1/2023.\n",
    "(5) An Introduction to Structured Data Markup - Web Design Envato Tuts+. https://webdesign.tutsplus.com/articles/an-introduction-to-structured-data-markup--webdesign-8577 Accessed 4/1/2023.\n",
    "\n",
    "----\n",
    "\n",
    "Additional Resources\n",
    "\n",
    "-----\n",
    "Source: Conversation with Bing, 4/1/2023\n",
    "(1) Dataset Structured Data | Google Search Central | Documentation .... https://developers.google.com/search/docs/appearance/structured-data/dataset Accessed 4/1/2023.\n",
    "(2) csv-ld · PyPI. https://pypi.org/project/csv-ld/ Accessed 4/1/2023.\n",
    "(3) Generating JSON from Tabular Data on the Web - GitHub Pages. https://w3c.github.io/csvw/csv2json/ Accessed 4/1/2023.\n",
    "(4) CSV-LD - CSV on the Web Working Group Wiki - W3. https://www.w3.org/2013/csvw/wiki/CSV-LD Accessed 4/1/2023.\n",
    "(5) compact_json_ld: Compact objects to values in csvwr: Read and Write CSV .... https://rdrr.io/cran/csvwr/man/compact_json_ld.html Accessed 4/1/2023.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "**Me**\n",
    "> I have a csv that contains the following data: id,name,age,city 1,Alice,30,New York 2,Bob,25,Los Angeles 3,Carol,22,Chicago Can you help me to create a proper CSVW for this file?\n",
    "---------------\n",
    "**Bing**\n",
    "\n",
    "Sure, I can help you with that. CSVW is a W3C standard for describing the data stored in CSV files using an additional metadata.json file². It is designed to be flexible and suitable for many different types of data. A CSVW-described dataset is basically equivalent to a Frictionless DataPackage where all Data Resources are Tabular Data¹.\n",
    "\n",
    "To create a proper CSVW for your file, you need to create a metadata.json file that describes the structure and semantics of your CSV file. The metadata.json file should contain the following information:\n",
    "\n",
    "- A @context property that specifies the CSVW namespace and context.\n",
    "- A tables property that contains an array of table descriptions, one for each CSV file in the dataset.\n",
    "- Each table description should have a url property that specifies the location of the CSV file, and a tableSchema property that describes the columns and rows of the table.\n",
    "- Each tableSchema should have a columns property that contains an array of column descriptions, one for each column in the table.\n",
    "- Each column description should have a name property that specifies the name of the column, and optionally a datatype property that specifies the type and format of the values in the column.\n",
    "\n",
    "For example, a possible metadata.json file for your CSV file could look like this:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"@context\": \"http://www.w3.org/ns/csvw\",\n",
    "  \"tables\": [\n",
    "    {\n",
    "      \"url\": \"data.csv\",\n",
    "      \"tableSchema\": {\n",
    "        \"columns\": [\n",
    "          {\n",
    "            \"name\": \"id\",\n",
    "            \"datatype\": \"integer\"\n",
    "          },\n",
    "          {\n",
    "            \"name\": \"name\",\n",
    "            \"datatype\": \"string\"\n",
    "          },\n",
    "          {\n",
    "            \"name\": \"age\",\n",
    "            \"datatype\": \"integer\"\n",
    "          },\n",
    "          {\n",
    "            \"name\": \"city\",\n",
    "            \"datatype\": \"string\"\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "You can find more details and examples of CSVW metadata files at https://www.w3.org/TR/tabular-metadata/² and https://www.stevenfirth.com/csv-on-the-web-creating-descriptive-metadata-files/⁴.\n",
    "\n",
    "Source: Conversation with Bing, 4/1/2023(1) CSVW Namespace Vocabulary Terms - W3. https://www.w3.org/ns/csvw Accessed 4/1/2023.\n",
    "(2) csvw · PyPI. https://pypi.org/project/csvw/ Accessed 4/1/2023.\n",
    "(3) CSV on the Web: Creating descriptive metadata files - Steven Firth. https://www.stevenfirth.com/csv-on-the-web-creating-descriptive-metadata-files/ Accessed 4/1/2023.\n",
    "(4) CSV on the Web: Working with units of measure. https://www.stevenfirth.com/csv-on-the-web-working-with-units-of-measure/ Accessed 4/1/2023.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Me**\n",
    "> Can you give me the python that will do this?\n",
    "----\n",
    "\n",
    "**Bing**\n",
    "\n",
    "Sure, here is a possible python code that will do this:\n",
    "\n",
    "```python\n",
    "# Import the rdflib and csvw modules\n",
    "import rdflib\n",
    "import csvw\n",
    "\n",
    "# Create a rdflib graph object to store your RDF triples\n",
    "g = rdflib.Graph()\n",
    "\n",
    "# Use the csvw.CSVW method to parse your CSV file and metadata file and convert them to RDF\n",
    "data = csvw.CSVW('data.csv', metadata='metadata.json')\n",
    "\n",
    "# Use the data.to_rdf method to add the RDF triples to your graph object\n",
    "data.to_rdf(g)\n",
    "\n",
    "# Optionally, you can serialize your graph object to a file or a string in various RDF formats\n",
    "g.serialize(format='turtle')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "CSVW.__init__() got an unexpected keyword argument 'tableSchema'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m g \u001b[39m=\u001b[39m rdflib\u001b[39m.\u001b[39mGraph()\n\u001b[1;32m      8\u001b[0m \u001b[39m# Use the csvw.CSVW method to parse your CSV file and metadata file and convert them to RDF\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m data \u001b[39m=\u001b[39m csvw\u001b[39m.\u001b[39;49mCSVW(\u001b[39m'\u001b[39;49m\u001b[39mpeople.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, tableSchema\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpeople.csvw.json\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     11\u001b[0m \u001b[39m# Use the data.to_rdf method to add the RDF triples to your graph object\u001b[39;00m\n\u001b[1;32m     12\u001b[0m data\u001b[39m.\u001b[39mto_rdf(g)\n",
      "\u001b[0;31mTypeError\u001b[0m: CSVW.__init__() got an unexpected keyword argument 'tableSchema'"
     ]
    }
   ],
   "source": [
    "# Import the rdflib and csvw modules\n",
    "import rdflib\n",
    "import csvw\n",
    "\n",
    "# Create a rdflib graph object to store your RDF triples\n",
    "g = rdflib.Graph()\n",
    "\n",
    "# Use the csvw.CSVW method to parse your CSV file and metadata file and convert them to RDF\n",
    "data = csvw.CSVW('people.csv', tableSchema='people.csvw.json')\n",
    "\n",
    "# Use the data.to_rdf method to add the RDF triples to your graph object\n",
    "data.to_rdf(g)\n",
    "\n",
    "# Optionally, you can serialize your graph object to a file or a string in various RDF formats\n",
    "print(g.serialize(format='turtle'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Unfortunately, Bing chat halucinates this function interface definition to the CSVW library. Let's try OpenAI ChatGPT.\n",
    "\n",
    "------\n",
    "\n",
    "## ChatGPT's turn!\n",
    "\n",
    "\n",
    "**Me**\n",
    "I have a csv that contains the following data: id,name,age,city 1,Alice,30,New York 2,Bob,25,Los Angeles 3,Carol,22,Chicago Can you help me to create a proper CSVW for this file?\n",
    "\n",
    "-----\n",
    "\n",
    "**ChatGPT**\n",
    "\n",
    "Certainly! CSVW (CSV on the Web) is a way to provide additional metadata about your CSV files, which helps other tools and applications better understand the structure and contents of your files. To create a CSVW file, you'll need to write a JSON file containing the metadata.\n",
    "\n",
    "Here's a JSON file that describes your CSV data:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"@context\": \"http://www.w3.org/ns/csvw\",\n",
    "  \"@id\": \"http://example.org/your-csv-file.csv\",\n",
    "  \"url\": \"http://example.org/your-csv-file.csv\",\n",
    "  \"tableSchema\": {\n",
    "    \"columns\": [\n",
    "      {\n",
    "        \"name\": \"id\",\n",
    "        \"titles\": \"ID\",\n",
    "        \"datatype\": \"integer\",\n",
    "        \"propertyUrl\": \"http://example.org/vocab/id\"\n",
    "      },\n",
    "      {\n",
    "        \"name\": \"name\",\n",
    "        \"titles\": \"Name\",\n",
    "        \"datatype\": \"string\",\n",
    "        \"propertyUrl\": \"http://example.org/vocab/name\"\n",
    "      },\n",
    "      {\n",
    "        \"name\": \"age\",\n",
    "        \"titles\": \"Age\",\n",
    "        \"datatype\": \"integer\",\n",
    "        \"propertyUrl\": \"http://example.org/vocab/age\"\n",
    "      },\n",
    "      {\n",
    "        \"name\": \"city\",\n",
    "        \"titles\": \"City\",\n",
    "        \"datatype\": \"string\",\n",
    "        \"propertyUrl\": \"http://example.org/vocab/city\"\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "This JSON file provides metadata for your CSV file, such as the data types of each column and their titles. Make sure to replace the @id and url properties with the correct URL of your CSV file. Save this JSON file with a .json extension, and it will serve as the CSVW metadata for your CSV file.\n",
    "\n",
    "To link the CSV file to the CSVW metadata file, you can add a Link header in the HTTP response, like this:\n",
    "\n",
    "```bash\n",
    "Link: <http://example.org/your-csvw-metadata.json>; rel=\"describedby\"\n",
    "```\n",
    "\n",
    "Or, if you can't modify the HTTP headers, you can add a comment at the beginning of the CSV file, like this:\n",
    "\n",
    "```csv\n",
    "#csvw-metadata:http://example.org/your-csvw-metadata.json\n",
    "id,name,age,city\n",
    "1,Alice,30,New York\n",
    "2,Bob,25,Los Angeles\n",
    "3,Carol,22,Chicago\n",
    "```\n",
    "\n",
    "Remember to replace the URLs with the actual URLs of your files."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Me**\n",
    "How do I generate a RDF Knowledge Graph from this metadata using rdflib and the csvw library?\n",
    "\n",
    "-------\n",
    "\n",
    "**ChatGPT**\n",
    "To generate an RDF Knowledge Graph from the CSVW metadata, you can use the csvw library to parse the CSV file and metadata, and then use the rdflib library to manage the RDF graph. Here's a step-by-step guide:\n",
    "\n",
    "1 .First, make sure you have both csvw and rdflib installed. You can install them using pip:\n",
    "\n",
    "``bash\n",
    "pip install csvw rdflib\n",
    "```\n",
    "\n",
    "2. Next, create a Python script and import the necessary libraries:\n",
    "\n",
    "```python\n",
    "import csvw\n",
    "import rdflib\n",
    "from io import StringIO\n",
    "```\n",
    "\n",
    "3. Load the CSV file and its corresponding CSVW metadata file:\n",
    "\n",
    "```python\n",
    "csv_file_path = 'your-csv-file.csv'\n",
    "metadata_file_path = 'your-csvw-metadata.json'\n",
    "\n",
    "metadata = csvw.TableGroup.from_file(metadata_file_path)\n",
    "table = metadata.tables[0]\n",
    "\n",
    "table.url = csv_file_path\n",
    "```\n",
    "\n",
    "4. Convert the CSV file to an RDF Knowledge Graph using the to_rdf method:\n",
    "\n",
    "```python\n",
    "rdf_output = StringIO()\n",
    "table.to_rdf(rdf_output, format='turtle')\n",
    "rdf_output.seek(0)\n",
    "```\n",
    "\n",
    "5. Create an rdflib graph and load the generated RDF data:\n",
    "\n",
    "```python\n",
    "graph = rdflib.Graph()\n",
    "graph.parse(data=rdf_output.read(), format='turtle')\n",
    "```\n",
    "\n",
    "6. Now you have an RDF Knowledge Graph stored in the graph variable, and you can perform various operations on it, like querying or serializing:\n",
    "\n",
    "```python\n",
    "# Query the graph\n",
    "query = '''\n",
    "    PREFIX vocab: <http://example.org/vocab/>\n",
    "    SELECT ?name ?city\n",
    "    WHERE {\n",
    "        ?s vocab:name ?name .\n",
    "        ?s vocab:city ?city .\n",
    "    }\n",
    "'''\n",
    "\n",
    "results = graph.query(query)\n",
    "for result in results:\n",
    "    print(f\"Name: {result['name']}, City: {result['city']}\")\n",
    "\n",
    "# Serialize the graph in a different RDF format (e.g., N-Triples)\n",
    "serialized_graph = graph.serialize(format='nt').decode('utf-8')\n",
    "print(serialized_graph)\n",
    "```\n",
    "\n",
    "This script demonstrates how to use the csvw library to parse the CSV file and its CSVW metadata, then convert it to an RDF Knowledge Graph using rdflib. You can customize the script by replacing the file paths and adjusting the query or serialization format as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Table' object has no attribute 'to_rdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# Convert CSV to RDF\u001b[39;00m\n\u001b[1;32m     14\u001b[0m rdf_output \u001b[39m=\u001b[39m StringIO()\n\u001b[0;32m---> 15\u001b[0m table\u001b[39m.\u001b[39;49mto_rdf(rdf_output, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mturtle\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m rdf_output\u001b[39m.\u001b[39mseek(\u001b[39m0\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[39m# Load RDF data into an rdflib graph\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Table' object has no attribute 'to_rdf'"
     ]
    }
   ],
   "source": [
    "import csvw\n",
    "import rdflib\n",
    "from io import StringIO\n",
    "\n",
    "# Load CSV and CSVW metadata files\n",
    "csv_file_path = 'people.csv'\n",
    "metadata_file_path = 'people.csvw.json'\n",
    "\n",
    "metadata = csvw.TableGroup.from_file(metadata_file_path)\n",
    "table = metadata.tables[0]\n",
    "table.url = csv_file_path\n",
    "\n",
    "# Convert CSV to RDF\n",
    "rdf_output = StringIO()\n",
    "table.to_rdf(rdf_output, format='turtle')\n",
    "rdf_output.seek(0)\n",
    "\n",
    "# Load RDF data into an rdflib graph\n",
    "graph = rdflib.Graph()\n",
    "graph.parse(data=rdf_output.read(), format='turtle')\n",
    "\n",
    "# Query the graph\n",
    "query = '''\n",
    "    PREFIX vocab: <http://example.org/vocab/>\n",
    "    SELECT ?name ?city\n",
    "    WHERE {\n",
    "        ?s vocab:name ?name .\n",
    "        ?s vocab:city ?city .\n",
    "    }\n",
    "'''\n",
    "\n",
    "results = graph.query(query)\n",
    "for result in results:\n",
    "    print(f\"Name: {result['name']}, City: {result['city']}\")\n",
    "\n",
    "# Serialize the graph in a different RDF format (e.g., N-Triples)\n",
    "serialized_graph = graph.serialize(format='nt').decode('utf-8')\n",
    "print(serialized_graph)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few problems with this code. First, the interface function table.to_rdf() doesn't exist. Second, it ChatGPT forgets that the KG is a string not binary so **ALWAYS** wants to use the decode method on the graph.serialize method which is not needed:\n",
    "\n",
    "``python\n",
    "serialized_graph = graph.serialize(format='nt').decode('utf-8')\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A correct set of code would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"id\": 1,\n",
      "        \"name\": \"Alice\",\n",
      "        \"age\": 30,\n",
      "        \"city\": \"New York\"\n",
      "    },\n",
      "    {\n",
      "        \"id\": 2,\n",
      "        \"name\": \"Bob\",\n",
      "        \"age\": 25,\n",
      "        \"city\": \"Los Angeles\"\n",
      "    },\n",
      "    {\n",
      "        \"id\": 3,\n",
      "        \"name\": \"Carol\",\n",
      "        \"age\": 22,\n",
      "        \"city\": \"Chicago\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from csvw import CSVW\n",
    "from rdflib import Graph, Namespace\n",
    "\n",
    "metadata_path = \"people.csvw.json\"\n",
    "\n",
    "# Load the CSVW data using the metadata file\n",
    "data = CSVW(metadata_path)\n",
    "\n",
    "# Convert the data to JSON\n",
    "json_data = data.to_json(minimal=True)\n",
    "\n",
    "# Pretty print the JSON data\n",
    "pretty_json = json.dumps(json_data, indent=4)\n",
    "print(pretty_json)\n",
    "\n",
    "# Create an RDF graph and parse the JSON-LD data\n",
    "g = Graph()\n",
    "#g.parse(data=json.dumps(json_data_with_context), format='json-ld')\n",
    "\n",
    "# Print the triples in the RDF graph\n",
    "#print(\"Triples in the RDF graph:\")\n",
    "#for s, p, o in g:\n",
    "#    print(f\"{s} {p} {o}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, this get's us JSON, which is pretty useful, but not JSON-LD or RDF. Let's ask Bing, if it can help us to get RDF.\n",
    "\n",
    "-------\n",
    "\n",
    "**Me**\n",
    "Now that I have a JSON object, how do I move that to RDF? Do I need a context?\n",
    "\n",
    "------\n",
    "\n",
    "**Bing**\n",
    "\n",
    "To convert JSON to RDF in Python, you need to have a way to map the JSON keys and values to RDF terms, such as URIs, literals, or blank nodes. One way to do this is to use JSON-LD, which is a standard format for expressing JSON data as linked data. JSON-LD allows you to add a `@context` property to your JSON object, which defines how the keys and values map to RDF vocabularies. For example, you can do something like this:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"@context\": {\n",
    "    \"name\": \"http://xmlns.com/foaf/0.1/name\",\n",
    "    \"age\": \"http://schema.org/age\"\n",
    "  },\n",
    "  \"name\": \"Bart Simpson\",\n",
    "  \"age\": \"11\"\n",
    "}\n",
    "```\n",
    "\n",
    "This JSON-LD object can be converted to RDF using a library like rdflib or pyld. For example, you can do something like this:\n",
    "\n",
    "```python\n",
    "import json\n",
    "from rdflib import Graph\n",
    "\n",
    "# Load the JSON-LD object\n",
    "json_ld = json.load(open(\"example.json\"))\n",
    "\n",
    "# Convert it to RDF graph\n",
    "g = Graph().parse(data=json.dumps(json_ld), format=\"json-ld\")\n",
    "\n",
    "# Serialize it to Turtle\n",
    "print(g.serialize(format=\"turtle\").decode())\n",
    "```\n",
    "\n",
    "This will output:\n",
    "\n",
    "```turtle\n",
    "@prefix ns1: <http://schema.org/> .\n",
    "@prefix ns2: <http://xmlns.com/foaf/0.1/> .\n",
    "\n",
    "<http://example.com/example.json> ns1:age \"11\" ;\n",
    "    ns2:name \"Bart Simpson\" .\n",
    "```\n",
    "\n",
    "You can also use other tools to convert JSON to RDF, such as JARQL or SPARQL Anything, which allow you to use SPARQL queries on JSON data and construct RDF triples. For more details, you can refer to some online resources¹²³⁴.\n",
    "\n",
    "Source: Conversation with Bing, 4/1/2023(1) Json to RDF/XML file in Python - Stack Overflow. https://stackoverflow.com/questions/29030231/json-to-rdf-xml-file-in-python Accessed 4/1/2023.\n",
    "(2) rdf - converting json to turtle - Stack Overflow. https://stackoverflow.com/questions/66444079/converting-json-to-turtle Accessed 4/1/2023.\n",
    "(3) Convert JSON to PDF in Python - Aspose Documentation. https://products.aspose.com/cells/python-net/conversion/json-to-pdf/ Accessed 4/1/2023.\n",
    "(4) Convert JSON to PDF via Python | products.aspose.com. https://products.aspose.com/cells/python-java/conversion/json-to-pdf/ Accessed 4/1/2023.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "**Me**\n",
    "I have the following turtle vocabulary for my CSV, can you generate the context as you described it in the previous chat? @prefix ex: <http://example.org/> . @prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> . @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> . @prefix xsd: <http://www.w3.org/2001/XMLSchema#> . ex:Person a rdfs:Class ; rdfs:label \"Person\" . ex:name a rdf:Property ; rdfs:label \"name\" ; rdfs:domain ex:Person ; rdfs:range rdfs:Literal . ex:age a rdf:Property ; rdfs:label \"age\" ; rdfs:domain ex:Person ; rdfs:range xsd:integer . ex:city a rdf:Property ; rdfs:label \"city\" ; rdfs:domain ex:Person ; rdfs:range rdfs:Literal .\n",
    "Sent message. I have the following turtle vocabulary for my CSV, can you generate the context as you described it in the previous chat? @prefix ex: <http://example.org/> . @prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> . @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> . @prefix xsd: <http://www.w3.org/2001/XMLSchema#> . ex:Person a rdfs:Class ; rdfs:label \"Person\" . ex:name a rdf:Property ; rdfs:label \"name\" ; rdfs:domain ex:Person ; rdfs:range rdfs:Literal . ex:age a rdf:Property ; rdfs:label \"age\" ; rdfs:domain ex:Person ; rdfs:range xsd:integer . ex:city a rdf:Property ; rdfs:label \"city\" ; rdfs:domain ex:Person ; rdfs:range rdfs:Literal .\n",
    "\n",
    "------\n",
    "\n",
    "**Bing**\n",
    "\n",
    "To generate the context for your turtle vocabulary, you can use the following JSON-LD object:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"@context\": {\n",
    "    \"ex\": \"http://example.org/\",\n",
    "    \"rdf\": \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\",\n",
    "    \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\",\n",
    "    \"xsd\": \"http://www.w3.org/2001/XMLSchema#\",\n",
    "    \"Person\": \"ex:Person\",\n",
    "    \"name\": {\n",
    "      \"@id\": \"ex:name\",\n",
    "      \"@type\": \"rdfs:Literal\"\n",
    "    },\n",
    "    \"age\": {\n",
    "      \"@id\": \"ex:age\",\n",
    "      \"@type\": \"xsd:integer\"\n",
    "    },\n",
    "    \"city\": {\n",
    "      \"@id\": \"ex:city\",\n",
    "      \"@type\": \"rdfs:Literal\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "This context defines the prefixes and terms that correspond to your turtle vocabulary. You can use this context to convert your CSV data to JSON-LD and then to RDF. For example, if you have a CSV file like this:\n",
    "\n",
    "```csv\n",
    "name,age,city\n",
    "Alice,25,London\n",
    "Bob,30,Paris\n",
    "Charlie,35,Berlin\n",
    "```\n",
    "\n",
    "You can convert it to JSON-LD using a tool like csv2jsonld:\n",
    "\n",
    "```bash\n",
    "csv2jsonld -c context.json -i data.csv -o data.jsonld\n",
    "```\n",
    "\n",
    "This will output a JSON-LD file like this:\n",
    "\n",
    "```json\n",
    "[\n",
    "  {\n",
    "    \"@context\": {\n",
    "      \"ex\": \"http://example.org/\",\n",
    "      \"rdf\": \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\",\n",
    "      \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\",\n",
    "      \"xsd\": \"http://www.w3.org/2001/XMLSchema#\",\n",
    "      \"Person\": \"ex:Person\",\n",
    "      \"name\": {\n",
    "        \"@id\": \"ex:name\",\n",
    "        \"@type\": \"rdfs:Literal\"\n",
    "      },\n",
    "      \"age\": {\n",
    "        \"@id\": \"ex:age\",\n",
    "        \"@type\": \"xsd:integer\"\n",
    "      },\n",
    "      \"city\": {\n",
    "        \"@id\": \"ex:city\",\n",
    "        \"@type\": \"rdfs:Literal\"\n",
    "      }\n",
    "    },\n",
    "    \"@type\": [\n",
    "      \"Person\"\n",
    "    ],\n",
    "    \"name\": [\n",
    "      {\n",
    "        \"@value\": \"Alice\"\n",
    "      }\n",
    "    ],\n",
    "    \"age\": [\n",
    "      {\n",
    "        \"@value\": 25\n",
    "      }\n",
    "    ],\n",
    "    \"city\": [\n",
    "      {\n",
    "        \"@value\": \"London\"\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"@context\": {\n",
    "      ...\n",
    "    },\n",
    "    \"@type\": [\n",
    "      ...\n",
    "    ],\n",
    "    ...\n",
    "  },\n",
    "  ...\n",
    "]\n",
    "```\n",
    "\n",
    "You can then convert this JSON-LD file to RDF using a library like rdflib or pyld. For example, you can do something like this:\n",
    "\n",
    "```python\n",
    "import json\n",
    "from rdflib import Graph\n",
    "\n",
    "# Load the JSON-LD file\n",
    "json_ld = json.load(open(\"data.jsonld\"))\n",
    "\n",
    "# Convert it to RDF graph\n",
    "g = Graph().parse(data=json.dumps(json_ld), format=\"json-ld\")\n",
    "\n",
    "# Serialize it to Turtle\n",
    "print(g.serialize(format=\"turtle\").decode())\n",
    "```\n",
    "\n",
    "This will output:\n",
    "\n",
    "```turtle\n",
    "@prefix ex: <http://example.org/> .\n",
    "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
    "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
    "\n",
    "_:N0a7e6f8a5f4a4c8b9e9b7c5a6b2f7f8d a ex:Person ;\n",
    "    ex:age 25 ;\n",
    "    ex:city \"London\" ;\n",
    "    ex:name \"Alice\" .\n",
    "\n",
    "_:N1b6c7d8b6f4b4d8a9f9a7c6a6b2f7f8d a ex:Person ;\n",
    "    ex:age 30 ;\n",
    "    ex:city \"Paris\" ;\n",
    "    ex:name \"Bob\" .\n",
    "\n",
    "_:N2c7e8d9c6f5c5e9bafab8d7b7c3g8g9d a ex:Person ;\n",
    "    ex:age 35 ;\n",
    "    ex:city \"Berlin\" ;\n",
    "    ex:name \"Charlie\" .\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
